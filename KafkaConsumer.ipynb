{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0d91946b-ba83-4a25-93d7-8e4464bcf556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "from time import sleep \n",
    "from json import dumps, loads\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7b0a44b0-977d-4205-906a-c9ce3c61d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer('demo_test',\n",
    "                         bootstrap_servers=['okore-joel:9092'],\n",
    "                         value_deserializer=lambda x:\n",
    "                         loads(x.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "178393f9-9511-4e10-925c-a7961c2ba7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category',\n",
    "       'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip',\n",
    "       'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time',\n",
    "       'merch_lat', 'merch_long', 'merch_zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "98224528-3985-4f9b-a8c8-968acff5e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine formula to calculate distance between two lat/long points in miles\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Radius of the Earth in miles\n",
    "    R = 3958.8\n",
    "    # Convert degrees to radians\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Vectorized calculation of distances\n",
    "def calculate_distance_vectorized(data):\n",
    "    data['distance'] = haversine(data['lat'], data['long'], data['merch_lat'], data['merch_long'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8992df52-b543-4af4-9455-1f8cb709be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "806ef2c3-892c-4213-a9ad-b34672c38239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-14 15:41:14.894698] Prediction for Anthony Allen || Transaction: c48f2efccb689f2daef9ebdb03e1edec || TRANSACTION ACCEPTED (Processed 0.006183 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:15.895525] Prediction for Daniel Boyd || Transaction: 68f2b98cba5c4ae6b7ff3f701d0cdc69 || TRANSACTION ACCEPTED (Processed 0.005163 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:16.898521] Prediction for Micheal Walters || Transaction: b832170811fa7ce7ec76d9af27adecd2 || TRANSACTION ACCEPTED (Processed 0.00639 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:17.901334] Prediction for Jeffrey Munoz || Transaction: 7bbb699e093e3fb7d16c96093e95d66f || TRANSACTION ACCEPTED (Processed 0.00716 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:18.904074] Prediction for Joanna Hudson || Transaction: 5666921b2c9a994021da1bdbb9aea908 || TRANSACTION ACCEPTED (Processed 0.007688 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:19.905652] Prediction for Christine Harris || Transaction: 72eefdc7ab123dfc9a4adee5aeae9e11 || TRANSACTION ACCEPTED (Processed 0.007197 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:20.907900] Prediction for Derek Jones || Transaction: ca0183f90d413fbc28e0a30912bfc386 || TRANSACTION ACCEPTED (Processed 0.007321 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:21.910246] Prediction for Monique Martin || Transaction: 99eff11c4cf99723aa5948d4953fa231 || TRANSACTION ACCEPTED (Processed 0.007351 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:22.912416] Prediction for Mary Mcintyre || Transaction: 3426f93e6dd6c750e19f6d12d8012d8b || TRANSACTION ACCEPTED (Processed 0.00735 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:23.914098] Prediction for Susan Washington || Transaction: e5286d527c34c801cc58f358ae474bc3 || TRANSACTION ACCEPTED (Processed 0.006694 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:24.917000] Prediction for Melissa Aguilar || Transaction: 40537913d201c71a2fb7a0d79d3182cd || TRANSACTION ACCEPTED (Processed 0.007345 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:25.918662] Prediction for Kathy Hughes || Transaction: 60ac00e69ae371273d7e82eaef640ebc || TRANSACTION ACCEPTED (Processed 0.006756 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:26.921078] Prediction for Ellen Smith || Transaction: 0d626c459b76e4595b9940a0246db2c2 || TRANSACTION DECLINED (Processed 0.007153 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:27.923561] Prediction for Morgan Murray || Transaction: da4f758f061182c4401389f5f2dd69cd || TRANSACTION ACCEPTED (Processed 0.007214 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:28.926258] Prediction for William Thompson || Transaction: 901fbff4382f014fe8cf680443272439 || TRANSACTION ACCEPTED (Processed 0.007592 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:29.928393] Prediction for Michael Gross || Transaction: 25ae058e0adb7a3a2894fc08c50ee2fb || TRANSACTION ACCEPTED (Processed 0.007398 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:30.930803] Prediction for Jeremy Chavez || Transaction: d6304c6b3f8ec0e06ae5420e66e8c65e || TRANSACTION DECLINED (Processed 0.007632 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:31.932446] Prediction for Tamara Martinez || Transaction: a82781ce17227e0110a79645927b576a || TRANSACTION DECLINED (Processed 0.006991 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:32.932962] Prediction for Belinda Jimenez || Transaction: 496397b607981290ba286a08c492ad37 || TRANSACTION DECLINED (Processed 0.005665 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:33.934900] Prediction for Stacy Lambert || Transaction: f20f61814a70d4a3fa695f77c04c36b9 || TRANSACTION ACCEPTED (Processed 0.005641 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:34.938495] Prediction for Joseph Gonzalez || Transaction: 3180b509f577a7fc89b56558f281a440 || TRANSACTION ACCEPTED (Processed 0.007354 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:35.939505] Prediction for John Nichols || Transaction: 8e1a81a23462b5e206c3cc6e97f84c6c || TRANSACTION DECLINED (Processed 0.006375 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:36.941677] Prediction for Micheal Hernandez || Transaction: 54c00372c7d1f0365c1cada0c1a374fe || TRANSACTION ACCEPTED (Processed 0.006317 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:37.944228] Prediction for Anthony Allen || Transaction: d5eaf6ab5d539306f711d8173a4079d5 || TRANSACTION ACCEPTED (Processed 0.006838 secs after production)\n",
      "\n",
      "[2024-10-14 15:41:38.946178] Prediction for Lawrence Davis || Transaction: b458c2aa09d7d3f000ebb808c69bfb2b || TRANSACTION ACCEPTED (Processed 0.006655 secs after production)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m categorical_cols \u001b[38;5;241m=\u001b[39m CSN_map[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_cols\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m numeric_cols \u001b[38;5;241m=\u001b[39m CSN_map[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric_cols\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconsumer\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Convert received data to DataFrame\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreceived_timestamp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml_env/lib/python3.12/site-packages/kafka/consumer/group.py:1203\u001b[0m, in \u001b[0;36mKafkaConsumer.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_v1()\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml_env/lib/python3.12/site-packages/kafka/consumer/group.py:1211\u001b[0m, in \u001b[0;36mKafkaConsumer.next_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_generator_v2()\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ml_env/lib/python3.12/site-packages/kafka/consumer/group.py:1126\u001b[0m, in \u001b[0;36mKafkaConsumer._message_generator_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_message_generator_v2\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1125\u001b[0m     timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consumer_timeout \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime())\n\u001b[0;32m-> 1126\u001b[0m     record_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tp, records \u001b[38;5;129;01min\u001b[39;00m record_map\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1128\u001b[0m         \u001b[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m records:\n\u001b[1;32m   1132\u001b[0m             \u001b[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m             \u001b[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m             \u001b[38;5;66;03m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m             \u001b[38;5;66;03m# via self._iterator = None\u001b[39;00m\n",
      "File \u001b[0;32m~/ml_env/lib/python3.12/site-packages/kafka/consumer/group.py:663\u001b[0m, in \u001b[0;36mKafkaConsumer.poll\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    661\u001b[0m remaining \u001b[38;5;241m=\u001b[39m timeout_ms\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[0;32m--> 663\u001b[0m     records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[1;32m    665\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m records\n",
      "File \u001b[0;32m~/ml_env/lib/python3.12/site-packages/kafka/consumer/group.py:712\u001b[0m, in \u001b[0;36mKafkaConsumer._poll_once\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpoll(timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    711\u001b[0m timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout_ms, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mtime_to_next_poll() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m--> 712\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mneed_rejoin():\n",
      "File \u001b[0;32m~/ml_env/lib/python3.12/site-packages/kafka/client_async.py:601\u001b[0m, in \u001b[0;36mKafkaClient.poll\u001b[0;34m(self, timeout_ms, future)\u001b[0m\n\u001b[1;32m    598\u001b[0m             timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretry_backoff_ms\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    599\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, timeout)  \u001b[38;5;66;03m# avoid negative timeouts\u001b[39;00m\n\u001b[0;32m--> 601\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# if handlers need to acquire locks\u001b[39;00m\n\u001b[1;32m    605\u001b[0m responses\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_pending_completed_requests())\n",
      "File \u001b[0;32m~/ml_env/lib/python3.12/site-packages/kafka/client_async.py:633\u001b[0m, in \u001b[0;36mKafkaClient._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_send_sockets()\n\u001b[1;32m    632\u001b[0m start_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 633\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m end_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sensors:\n",
      "File \u001b[0;32m/usr/lib/python3.12/selectors.py:468\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    466\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load CSN_map from the pickle file\n",
    "with open('CSN_map.pkl', 'rb') as f:\n",
    "    CSN_map = pickle.load(f)\n",
    "\n",
    "model = CSN_map['model']\n",
    "scaler = CSN_map['scaler']\n",
    "input_cols = CSN_map['input_cols']\n",
    "categorical_cols = CSN_map['categorical_cols']\n",
    "numeric_cols = CSN_map['numeric_cols']\n",
    "\n",
    "for message in consumer:\n",
    "    data = pd.DataFrame([message.value])  # Convert received data to DataFrame\n",
    "    received_timestamp = datetime.now()\n",
    "    \n",
    "    # Get the sent timestamp from the message\n",
    "    sent_timestamp = datetime.strptime(data['sent_timestamp'].values[0], '%Y-%m-%d %H:%M:%S.%f')\n",
    "    \n",
    "    # Calculate the time difference between producer and consumer\n",
    "    time_difference = received_timestamp - sent_timestamp\n",
    "\n",
    "    # Feature Engineering - date\n",
    "    data['trans_date_trans_time'] = pd.to_datetime(data['trans_date_trans_time'])\n",
    "    data['transaction_hour'] = data['trans_date_trans_time'].dt.hour\n",
    "    data['transaction_day_of_week'] = data['trans_date_trans_time'].dt.dayofweek\n",
    "    data['transaction_day'] = data['trans_date_trans_time'].dt.day\n",
    "\n",
    "    # Feature Engineering - others\n",
    "    data['amt'] = data['amt'].fillna(70.35103545607033)\n",
    "    data['merch_zipcode'] = data['merch_zipcode'].fillna(45860.0)\n",
    "    data['category'] = data['category'].fillna('gas_transport')\n",
    "    data['merchant'] = data['merchant'].fillna('fraud_Kilback LLC')\n",
    "    data['job'] = data['job'].fillna('Film/video editor')\n",
    "    data['state'] = data['state'].fillna('TX')\n",
    "\n",
    "    # Label (Gender) Encoder\n",
    "    data['gender'] = data['gender'].map({'M': 1, 'F': 0})\n",
    "\n",
    "    # One-hot encoding for categorical columns\n",
    "    data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Feature Engineering - age\n",
    "    data['dob'] = pd.to_datetime(data['dob'])\n",
    "    data['age'] = (pd.to_datetime('today') - data['dob']).dt.days // 365\n",
    "\n",
    "    # Feature Engineering - Haversine\n",
    "    data = calculate_distance_vectorized(data)\n",
    "    \n",
    "    # Scaling\n",
    "    data[numeric_cols] = scaler.transform(data[numeric_cols])\n",
    "\n",
    "    # Splitting and Preping (Droping irrelevant columns)\n",
    "    # exclude_columns = ['first', 'last', 'street', 'city', 'dob', 'trans_num', 'trans_date_trans_time', 'Unnamed: 0']\n",
    "    # data = data.drop(exclude_columns, axis=1)\n",
    "    \n",
    "    dataframe = data\n",
    "\n",
    "    first_name = data.loc[0, 'first']\n",
    "    last_name = data.loc[0, 'last']\n",
    "    trans_num = data.loc[0, 'trans_num']\n",
    "    \n",
    "     # Make predictions\n",
    "    prediction = model.predict(data[input_cols])\n",
    "\n",
    "    if prediction == 1:\n",
    "        print(f\"[{received_timestamp}] Prediction for {first_name} {last_name} || Transaction: {trans_num} || TRANSACTION DECLINED (Processed {time_difference.total_seconds()} secs after production)\\n\")\n",
    "    else:\n",
    "        print(f\"[{received_timestamp}] Prediction for {first_name} {last_name} || Transaction: {trans_num} || TRANSACTION ACCEPTED (Processed {time_difference.total_seconds()} secs after production)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8916d648-69a8-42e4-ae17-e483c426a5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
